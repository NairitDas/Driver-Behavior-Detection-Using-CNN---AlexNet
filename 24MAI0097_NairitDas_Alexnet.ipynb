{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Driver Safety Prediction\n"
      ],
      "metadata": {
        "id": "Ca-r09291wt_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUmFuSyG1dFm",
        "outputId": "66f941a9-05a7-4339-951d-3277caaf049a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download robinreni/revitsone-5class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWHm4Ag5KXIs",
        "outputId": "577bb4f7-7951-477b-955b-c083b56d2716"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/robinreni/revitsone-5class\n",
            "License(s): DbCL-1.0\n",
            "Downloading revitsone-5class.zip to /content\n",
            " 99% 977M/983M [00:11<00:00, 67.8MB/s]\n",
            "100% 983M/983M [00:11<00:00, 89.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Define the path to your downloaded zip file\n",
        "zip_file_path = '/content/revitsone-5class.zip'  # Change this to the actual path of your zip file\n",
        "\n",
        "# Define the destination folder for extraction\n",
        "extraction_folder = '/content/drive/MyDrive/DATA2/'  # Change this if you want to extract to a different folder\n",
        "\n",
        "# Check if the destination folder exists, if not, create it\n",
        "if not os.path.exists(extraction_folder):\n",
        "    os.makedirs(extraction_folder)\n",
        "\n",
        "# Extract the downloaded zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extraction_folder)\n",
        "\n",
        "print('Dataset extraction complete.')"
      ],
      "metadata": {
        "id": "3Fp4LzD5K4Jz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from numpy import asarray\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import glob\n",
        "import os\n",
        "import random\n",
        "import subprocess\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.io import imread\n",
        "from matplotlib.patches import Rectangle\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, Input, Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import BinaryCrossentropy"
      ],
      "metadata": {
        "id": "N6xcKbZxMKuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_list_other = []\n",
        "image_list_safe = []\n",
        "image_list_talking = []\n",
        "image_list_text = []\n",
        "image_list_turn = []\n",
        "\n",
        "# Update the base path to where the dataset was extracted\n",
        "base_path = '/content/drive/MyDrive/DATA2/Revitsone-5classes/'\n",
        "\n",
        "for other in os.listdir(os.path.join(base_path, \"other_activities\")):\n",
        "    if other.endswith(\".png\") or other.endswith(\".jpg\"):\n",
        "        image_list_other.append(os.path.join(base_path, \"other_activities\", other))\n",
        "        print(os.path.join(base_path, \"other_activities\", other))\n",
        "\n",
        "for safe in os.listdir(os.path.join(base_path, \"safe_driving\")):\n",
        "    if safe.endswith(\".png\") or safe.endswith(\".jpg\"):\n",
        "        image_list_safe.append(os.path.join(base_path, \"safe_driving\", safe))\n",
        "        print(os.path.join(base_path, \"safe_driving\", safe))\n",
        "\n",
        "for talking in os.listdir(os.path.join(base_path, \"talking_phone\")):\n",
        "    if talking.endswith(\".png\") or talking.endswith(\".jpg\"):\n",
        "        image_list_talking.append(os.path.join(base_path, \"talking_phone\", talking))\n",
        "        print(os.path.join(base_path, \"talking_phone\", talking))\n",
        "\n",
        "for text in os.listdir(os.path.join(base_path, \"texting_phone\")):\n",
        "    if text.endswith(\".png\") or text.endswith(\".jpg\"):\n",
        "        image_list_text.append(os.path.join(base_path, \"texting_phone\", text))\n",
        "        print(os.path.join(base_path, \"texting_phone\", text))\n",
        "\n",
        "for turn in os.listdir(os.path.join(base_path, \"turning\")):\n",
        "    if turn.endswith(\".png\") or turn.endswith(\".jpg\"):\n",
        "        image_list_turn.append(os.path.join(base_path, \"turning\", turn))\n",
        "        print(os.path.join(base_path, \"turning\", turn))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "390aZneqNc5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update the paths to match the actual paths in the lists.\n",
        "# The following example assumes that the base path is correct\n",
        "# but the other parts of the path are incorrect\n",
        "\n",
        "# Corrected paths for image_list_other\n",
        "image_list_other.remove('/content/drive/MyDrive/DATA2/Revitsone-5classes/other_activities/img_79.jpg')\n",
        "image_list_other.remove('/content/drive/MyDrive/DATA2/Revitsone-5classes/other_activities/img_4664.jpg')\n",
        "image_list_other.remove('/content/drive/MyDrive/DATA2/Revitsone-5classes/other_activities/img_7973.jpg')\n",
        "image_list_other.remove('/content/drive/MyDrive/DATA2/Revitsone-5classes/other_activities/img_13318.jpg')\n",
        "image_list_other.remove('/content/drive/MyDrive/DATA2/Revitsone-5classes/other_activities/img_13396.jpg')\n",
        "image_list_other.remove('/content/drive/MyDrive/DATA2/Revitsone-5classes/other_activities/img_13541.jpg')\n",
        "image_list_other.remove('/content/drive/MyDrive/DATA2/Revitsone-5classes/other_activities/img_13625.jpg')\n",
        "image_list_other.remove('/content/drive/MyDrive/DATA2/Revitsone-5classes/other_activities/img_20398.jpg')\n",
        "image_list_other.remove('/content/drive/MyDrive/DATA2/Revitsone-5classes/other_activities/img_22266.jpg')\n",
        "\n",
        "# Corrected paths for image_list_turn\n",
        "image_list_turn.remove('/content/drive/MyDrive/DATA2/Revitsone-5classes/turning/img_8771.jpg')\n",
        "image_list_turn.remove('/content/drive/MyDrive/DATA2/Revitsone-5classes/turning/img_62337.jpg')\n",
        "image_list_turn.remove('/content/drive/MyDrive/DATA2/Revitsone-5classes/turning/img_67523.jpg')\n",
        "image_list_turn.remove('/content/drive/MyDrive/DATA2/Revitsone-5classes/turning/img_70552.jpg')\n",
        "image_list_turn.remove('/content/drive/MyDrive/DATA2/Revitsone-5classes/turning/img_84605.jpg')\n",
        "image_list_turn.remove('/content/drive/MyDrive/DATA2/Revitsone-5classes/turning/img_101434.jpg')"
      ],
      "metadata": {
        "id": "ZtHEUQGHNoVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "font = {'family':'Times New Roman','color':'#1f211f'}\n",
        "background_color = '#fab72f'"
      ],
      "metadata": {
        "id": "xffjRv3LOGZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(1, figsize=(15, 9))\n",
        "\n",
        "# Adjust the position of the title above the subplots\n",
        "plt.subplots_adjust(top=0.85)  # Adjust the top margin for title spacing\n",
        "plt.axis('off')\n",
        "\n",
        "n = 0\n",
        "\n",
        "# Add the title and position it above the subplots\n",
        "plt.text(\n",
        "    0.5, 0.93, \"Random images of people who talk with their phone\",\n",
        "    ha='center', va='center', transform=plt.gcf().transFigure,\n",
        "    fontsize=25,\n",
        "    bbox=dict(facecolor='lightgray', alpha=0.8)\n",
        ")\n",
        "\n",
        "# Loop to add images in the subplots\n",
        "for i in range(4):\n",
        "    n += 1\n",
        "    random_img = random.choice(image_list_talking)\n",
        "    imgs = imread(random_img)\n",
        "    plt.subplot(2, 2, n)\n",
        "    plt.imshow(imgs)\n",
        "    plt.axis('off')  # Remove axis labels and ticks from subplots\n",
        "\n",
        "plt.tight_layout()  # Adjust layout to prevent overlap\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "u7iTTUDIPJko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.font_manager import FontProperties\n",
        "\n",
        "plt.figure(1, figsize=(15, 9))\n",
        "plt.axis('off')\n",
        "n = 0\n",
        "for i in range(4):\n",
        "    n += 1\n",
        "    random_img = random.choice(image_list_text)\n",
        "    imgs = imread(random_img)\n",
        "\n",
        "    # Create a FontProperties object with the desired font\n",
        "    font_prop = FontProperties(family=font['family'])  # Remove the 'color' argument\n",
        "\n",
        "    plt.suptitle(\"Random images of people who text with their phone\",\n",
        "                 fontproperties=font_prop, fontsize=25,\n",
        "                 backgroundcolor=background_color,\n",
        "                 color=font['color']) # Add the color argument to suptitle\n",
        "    plt.subplot(2, 2, n)\n",
        "    plt.imshow(imgs)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "e58rUZ1mPOKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(1, figsize=(15, 9))\n",
        "plt.axis('off')\n",
        "n = 0\n",
        "for i in range(4):\n",
        "\n",
        "    n += 1\n",
        "    random_img = random.choice(image_list_turn)\n",
        "    imgs = imread(random_img)\n",
        "    # Use font properties directly instead of fontdict\n",
        "    plt.suptitle(\"Random images of people who turn around\",\n",
        "                 fontsize=25,\n",
        "                 fontfamily=font['family'], # Use font['family'] for font family\n",
        "                 color=font['color'], # Use font['color'] for font color\n",
        "                 backgroundcolor=background_color)\n",
        "    plt.subplot(2,2,n)\n",
        "    plt.imshow(imgs)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fibtd0k8RCIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(1, figsize=(15, 9))\n",
        "plt.axis('off')\n",
        "n = 0\n",
        "for i in range(4):\n",
        "\n",
        "    n += 1\n",
        "    random_img = random.choice(image_list_safe)\n",
        "    imgs = imread(random_img)\n",
        "    plt.suptitle(\"Random images of people who drive safely\",\n",
        "                 fontsize=25,  # Removed 'fontdict' and used individual font properties\n",
        "                 fontfamily=font['family'],  # Set font family\n",
        "                 color=font['color'],  # Set font color\n",
        "                 backgroundcolor=background_color)\n",
        "    plt.subplot(2,2,n)\n",
        "    plt.imshow(imgs)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NSDcfKNsSm6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of samples in (Class = Other) = \" ,len(image_list_other))\n",
        "print(\"Number of samples in (Class = Safe Driving) = \" ,len(image_list_safe))\n",
        "print(\"Number of samples in (Class = Talking Phone) = \" ,len(image_list_talking))\n",
        "print(\"Number of samples in (Class = Texting Phone) = \" ,len(image_list_text))\n",
        "print(\"Number of samples in (Class = Turning) = \" ,len(image_list_turn))"
      ],
      "metadata": {
        "id": "vgLgJuQvVIdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(.75*len(image_list_other) , .2*len(image_list_other) ,.05*len(image_list_other))\n",
        "print(.75*len(image_list_safe) , .2*len(image_list_safe) ,.05*len(image_list_safe))\n",
        "print(.75*len(image_list_talking) , .2*len(image_list_talking) ,.05*len(image_list_talking))\n",
        "print(.75*len(image_list_text) , .2*len(image_list_text) ,.05*len(image_list_text))\n",
        "print(.75*len(image_list_turn) , .2*len(image_list_turn) ,.05*len(image_list_turn))"
      ],
      "metadata": {
        "id": "wksE6HdmVN1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train\",\"Test\", \"Valid\")\n",
        "\n",
        "train_other = image_list_other[:1589]\n",
        "test_other = image_list_other[1589:2012]\n",
        "valid_other = image_list_other[2012:]\n",
        "\n",
        "print (len(train_other), len(test_other), len(valid_other))\n",
        "\n",
        "train_safe = image_list_safe[:1652]\n",
        "test_safe = image_list_safe[1652:2092]\n",
        "valid_safe = image_list_safe[2092:]\n",
        "\n",
        "print (len(train_safe), len(test_safe), len(valid_safe))\n",
        "\n",
        "train_talking = image_list_talking[:1626]\n",
        "test_talking = image_list_talking[1626:2059]\n",
        "valid_talking = image_list_talking[2059:]\n",
        "\n",
        "print (len(train_talking), len(test_talking), len(valid_talking))\n",
        "\n",
        "train_text = image_list_text[:1652]\n",
        "test_text = image_list_text[1652:2092]\n",
        "valid_text = image_list_text[2092:]\n",
        "\n",
        "print (len(train_text), len(test_text), len(valid_text))\n",
        "\n",
        "train_turn = image_list_turn[:1547]\n",
        "test_turn = image_list_turn[1547:1959]\n",
        "valid_turn = image_list_turn[1959:]\n",
        "\n",
        "print (len(train_turn), len(test_turn), len(valid_turn))"
      ],
      "metadata": {
        "id": "ASCs52AdVPgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_other_df = pd.DataFrame({'image':train_other, 'label':'Other'})\n",
        "train_safe_df = pd.DataFrame({'image':train_safe, 'label':'Safe'})\n",
        "train_talking_df = pd.DataFrame({'image':train_talking, 'label':'Talk'})\n",
        "train_text_df = pd.DataFrame({'image':train_text, 'label':'Text'})\n",
        "train_turn_df = pd.DataFrame({'image':train_turn, 'label':'Turn'})\n",
        "test_other_df = pd.DataFrame({'image':test_other, 'label':'Other'})\n",
        "test_safe_df = pd.DataFrame({'image':test_safe, 'label':'Safe'})\n",
        "test_talking_df = pd.DataFrame({'image':test_talking, 'label':'Talk'})\n",
        "test_text_df = pd.DataFrame({'image':test_text, 'label':'Text'})\n",
        "test_turn_df = pd.DataFrame({'image':test_turn, 'label':'Turn'})"
      ],
      "metadata": {
        "id": "jYM5FRrkVew9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_other_df = pd.DataFrame({'image':valid_other, 'label':'Other'})\n",
        "valid_safe_df = pd.DataFrame({'image':valid_safe, 'label':'Safe'})\n",
        "valid_talking_df = pd.DataFrame({'image':valid_talking, 'label':'Talk'})\n",
        "valid_text_df = pd.DataFrame({'image':valid_text, 'label':'Text'})\n",
        "valid_turn_df = pd.DataFrame({'image':valid_turn, 'label':'Turn'})\n",
        "train_df = pd.concat([train_other_df, train_safe_df, train_talking_df, train_text_df, train_turn_df])\n",
        "test_df = pd.concat([test_other_df, test_safe_df, test_talking_df, test_text_df, test_turn_df])\n",
        "val_df = pd.concat([valid_other_df, valid_safe_df, valid_talking_df, valid_text_df, valid_turn_df])"
      ],
      "metadata": {
        "id": "YrDHIwfkVmXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "id": "TDYo5FpZVpH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of rows in train dataframe is: \", len(train_df))\n",
        "print(\"Number of rows in test dataframe is: \", len(test_df))\n",
        "print(\"Number of rows in val dataframe is: \", len(val_df))"
      ],
      "metadata": {
        "id": "L-ElV9NzVxCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_img_height = random.choice(train_other)\n",
        "image= cv2.imread(random_img_height)\n",
        "\n",
        "height, width= image.shape[:2]\n",
        "\n",
        "print(\"The height is \", height)\n",
        "\n",
        "print(\"The width is \", width)"
      ],
      "metadata": {
        "id": "iCWymiH-V28H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Batch_size = 64\n",
        "Img_height = 240\n",
        "Img_width = 240"
      ],
      "metadata": {
        "id": "O0jRTqr1V94H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainGenerator = ImageDataGenerator(rescale=1./255.)\n",
        "valGenerator = ImageDataGenerator(rescale=1./255.)\n",
        "testGenerator = ImageDataGenerator(rescale=1./255.)"
      ],
      "metadata": {
        "id": "SPIhVl80WHdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainDataset = trainGenerator.flow_from_dataframe(\n",
        "  dataframe=train_df,\n",
        "  class_mode=\"categorical\",\n",
        "  x_col=\"image\",\n",
        "  y_col=\"label\",\n",
        "  batch_size=Batch_size,\n",
        "  seed=42,\n",
        "  shuffle=True,\n",
        "  target_size=(Img_height,Img_width) #set the height and width of the images\n",
        ")\n",
        "\n",
        "testDataset = testGenerator.flow_from_dataframe(\n",
        "  dataframe=test_df,\n",
        "  class_mode='categorical',\n",
        "  x_col=\"image\",\n",
        "  y_col=\"label\",\n",
        "  batch_size=Batch_size,\n",
        "  seed=42,\n",
        "  shuffle=True,\n",
        "  target_size=(Img_height,Img_width)\n",
        ")\n",
        "\n",
        "valDataset = valGenerator.flow_from_dataframe(\n",
        "  dataframe=val_df,\n",
        "  class_mode='categorical',\n",
        "  x_col=\"image\",\n",
        "  y_col=\"label\",\n",
        "  batch_size=Batch_size,\n",
        "  seed=42,\n",
        "  shuffle=True,\n",
        "  target_size=(Img_height,Img_width)\n",
        ")"
      ],
      "metadata": {
        "id": "Xj6st7AcWKns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ngf29KnYWPfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def AlexNet():\n",
        "    inp = layers.Input((240, 240, 3))\n",
        "    x = layers.Conv2D(96, 11, 4, activation='relu')(inp)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D(3, 2)(x)\n",
        "    x = layers.Conv2D(256, 5, 1, activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D(3, 2)(x)\n",
        "    x = layers.Conv2D(384, 3, 1, activation='relu')(x)\n",
        "    x = layers.Conv2D(384, 3, 1, activation='relu')(x)\n",
        "    x = layers.Conv2D(256, 3, 1, activation='relu')(x)\n",
        "    x = layers.MaxPooling2D(3, 2)(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(4096, activation='relu')(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    x = layers.Dense(4096, activation='relu')(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    x = layers.Dense(5, activation='softmax')(x)\n",
        "\n",
        "    model_Alex = models.Model(inputs=inp, outputs=x)\n",
        "\n",
        "    return model_Alex\n",
        "\n",
        "model_Alex = AlexNet()\n",
        "model_Alex.summary()"
      ],
      "metadata": {
        "id": "D_TJXYsfS71L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(\n",
        "    model_Alex,\n",
        "    to_file='alex_model.png',\n",
        "    show_shapes=True,\n",
        "    show_dtype=False,\n",
        "    show_layer_names=True,\n",
        "    show_layer_activations=True,\n",
        "    dpi=100\n",
        ")"
      ],
      "metadata": {
        "id": "4aNdF4F_TdWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# epochs"
      ],
      "metadata": {
        "id": "Uw_dmVKNkTSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_Alex.compile(loss=BinaryCrossentropy(),\n",
        "              optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "hkoXK5O4ThQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Alex_model = model_Alex.fit(trainDataset, epochs=20, validation_data=valDataset)"
      ],
      "metadata": {
        "id": "3MDyqgxYTuea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_loss_alex = Alex_model.history['loss']\n",
        "val_loss_alex = Alex_model.history['val_loss']\n",
        "training_acc_alex = Alex_model.history['accuracy']\n",
        "val_acc_alex = Alex_model.history['val_accuracy']\n",
        "epoch_count = range(1, len(training_loss_alex) + 1)\n",
        "\n",
        "# Visualize loss history\n",
        "plt.figure(figsize=(8,3), dpi=200)\n",
        "plt.plot(epoch_count, training_loss_alex, 'r--', color= 'navy')\n",
        "plt.plot(epoch_count, val_loss_alex, '--bo',color= 'orangered', linewidth = '2.5', label='line with marker')\n",
        "plt.legend(['Training Loss', 'Val Loss'])\n",
        "plt.title('Number of epochs & Loss in ALEXNET')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.xticks(np.arange(1,21,1))\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "S-zZtoLpTyfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5), dpi=200)\n",
        "plt.plot(epoch_count, training_acc_alex, 'r--', color= 'navy')\n",
        "plt.plot(epoch_count, val_acc_alex, '--bo',color= 'orangered', linewidth = '2.5', label='line with marker')\n",
        "plt.legend(['Training Acc', 'Val Acc'])\n",
        "plt.title('Number of epochs & Accuracy in ALEXNET')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Acc')\n",
        "plt.xticks(np.arange(1,21,1))\n",
        "plt.plot();\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "HGdFr44RauAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dc1qyYsXa7uy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}